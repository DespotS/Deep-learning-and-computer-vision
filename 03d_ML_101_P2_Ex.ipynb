{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise on Machine Learning 101 - Part 2\n",
    "---\n",
    "Instructions are given in <span style=\"color:blue\">blue</span> color.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Created by:\n",
    "##### Tomislav Tomov 6003618\n",
    "##### Ioana Stoicescu 6003487"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will work with decision trees to (hopefully) further improve the classification results we got during the CRISP-DM lecture notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <div style=\"color:blue\">This week's material included an article by Pedro Domingos in which he gave a brief insight into the domain of Machine Learning. One of the papers' sections mentioned the usage of so-called <b>model ensembles</b>. Go back to the article, find the three techniques used for ensemble methods, as stated by Domingos, and cite his description for each one here.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your solution goes here:*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that email you send to your social worker friend? The one where you told him that you possibly need more data to get improved results out of your model? Well, he replied and stated that, unfortunately, there isn't any more data he could provide to you.\n",
    "It seems there is nothing left you can do but to go back to the drawing board for the second iteration of your modeling phase.\n",
    "\n",
    "* <div style=\"color:blue\">The folder <code>/data</code>, next to this exercise, contains the file <code>Student_Survey.csv</code>. Read the data into a <code>DataFrame</code> and make sure to import any necessary libraries, too.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sex  age address famsize Pstatus     Mjob      Fjob  studytime  failures  \\\n",
      "0   F   18       U     GT3       A  at_home   teacher          2         0   \n",
      "1   F   17       U     GT3       T  at_home     other          2         0   \n",
      "2   F   15       U     LE3       T  at_home     other          2         3   \n",
      "3   F   15       U     GT3       T   health  services          3         0   \n",
      "4   F   16       U     GT3       T    other     other          2         0   \n",
      "\n",
      "  activities  ... famrel freetime goout Dalc  Walc  health  absences  G1  G2  \\\n",
      "0         no  ...      4        3     4    1     1       3         6   5   6   \n",
      "1         no  ...      5        3     3    1     1       3         4   5   5   \n",
      "2         no  ...      4        3     2    2     3       3        10   7   8   \n",
      "3        yes  ...      3        2     2    1     1       5         2  15  14   \n",
      "4         no  ...      4        3     2    1     2       5         4   6  10   \n",
      "\n",
      "   G3  \n",
      "0   6  \n",
      "1   6  \n",
      "2  10  \n",
      "3  15  \n",
      "4  10  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./data/Student_Survey.csv\")\n",
    "\n",
    "# we can also show the amount of samples and columns\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is needed for **reproducibility** (see [here](https://www.mikulskibartosz.name/how-to-set-the-global-random_state-in-scikit-learn/), but also [here](https://scikit-learn.org/stable/faq.html#how-do-i-set-a-random-state-for-an-entire-execution)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "RSEED = 42\n",
    "np.random.seed(RSEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without seed\n",
      "[10.49671415  9.8617357  10.64768854 11.52302986]\n",
      "[ 9.76584663  9.76586304 11.57921282 10.76743473]\n",
      "With the same seed\n",
      "[10.49671415  9.8617357  10.64768854 11.52302986]\n",
      "[10.49671415  9.8617357  10.64768854 11.52302986]\n",
      "Without seed\n",
      "[11.47402845  9.4843798   9.93211866 10.63907642]\n",
      "[ 8.443523   10.24290282 10.19171778  8.98428159]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "print('Without seed')\n",
    "print(norm.rvs(10, size = 4))\n",
    "print(norm.rvs(10, size = 4))\n",
    "\n",
    "print('With the same seed')\n",
    "np.random.seed(42)\n",
    "print(norm.rvs(10, size = 4))\n",
    "np.random.seed(42) # reset the random seed back to 42\n",
    "print(norm.rvs(10, size = 4))\n",
    "\n",
    "print('Without seed')\n",
    "np.random.seed(None)\n",
    "print(norm.rvs(10, size = 4))\n",
    "print(norm.rvs(10, size = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <div style=\"color:blue\">Remove the columns <code>G1</code>, <code>G2</code>, <code>G3</code>, and <code>Walc</code> from your <code>DataFrame</code>.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['G1', 'G2', 'G3', 'Walc'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <div style=\"color:blue\">Replace all categorical values in your <code>DataFrame</code> with numerical data - using an appropriate method.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['F', 'M'], dtype=object),\n",
       " array(['R', 'U'], dtype=object),\n",
       " array(['GT3', 'LE3'], dtype=object),\n",
       " array(['A', 'T'], dtype=object),\n",
       " array(['at_home', 'health', 'other', 'services', 'teacher'], dtype=object),\n",
       " array(['at_home', 'health', 'other', 'services', 'teacher'], dtype=object),\n",
       " array(['no', 'yes'], dtype=object),\n",
       " array(['no', 'yes'], dtype=object),\n",
       " array(['no', 'yes'], dtype=object),\n",
       " array(['no', 'yes'], dtype=object),\n",
       " array(['no', 'yes'], dtype=object)]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Create an encoder instance\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# Create a list that holds columns with categorical data\n",
    "oe_columns = [\"sex\", \"address\", \"famsize\", \"Pstatus\", \"Mjob\", \"Fjob\", \"activities\", \"nursery\", \"higher\", \"internet\", \"romantic\"]\n",
    "\n",
    "# Retrieve the categories from those columns\n",
    "encoder.fit(data[oe_columns])\n",
    "\n",
    "# Map the categories to numerical data in the original data frame\n",
    "data[oe_columns] = encoder.transform(data[oe_columns])\n",
    "\n",
    "encoder.categories_\n",
    "#print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    GT3\n",
       "1    GT3\n",
       "2    LE3\n",
       "3    GT3\n",
       "4    GT3\n",
       "Name: famsize, dtype: object"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invert the transformation to retrieve the original categorical values from a column\n",
    "pd.DataFrame(encoder.inverse_transform(data[oe_columns]), columns=oe_columns).famsize.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  address  famsize  Pstatus  Mjob  Fjob  studytime  failures  \\\n",
       "0  0.0   18      1.0      0.0      0.0   0.0   4.0          2         0   \n",
       "1  0.0   17      1.0      0.0      1.0   0.0   2.0          2         0   \n",
       "2  0.0   15      1.0      1.0      1.0   0.0   2.0          2         3   \n",
       "3  0.0   15      1.0      0.0      1.0   1.0   3.0          3         0   \n",
       "4  0.0   16      1.0      0.0      1.0   2.0   2.0          2         0   \n",
       "\n",
       "   activities  nursery  higher  internet  romantic  famrel  freetime  goout  \\\n",
       "0         0.0      1.0     1.0       0.0       0.0       4         3      4   \n",
       "1         0.0      0.0     1.0       1.0       0.0       5         3      3   \n",
       "2         0.0      1.0     1.0       1.0       0.0       4         3      2   \n",
       "3         1.0      1.0     1.0       1.0       1.0       3         2      2   \n",
       "4         0.0      1.0     1.0       0.0       0.0       4         3      2   \n",
       "\n",
       "   Dalc  health  absences  \n",
       "0     1       3         6  \n",
       "1     1       3         4  \n",
       "2     2       3        10  \n",
       "3     1       5         2  \n",
       "4     1       5         4  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main issues present in our data is that the classes are highly **imbalanced**. This effect can be seen rather often when performing classification tasks and means that there is a different number of total samples for each present class. Usually, imbalanced classes make it much harder to successfully fit a model. In our case, this imbalance is quite drastic.\n",
    "* <div style=\"color:blue\">Confirm, both visually and numerically, that the classes in your <code>DataFrame</code> are imbalanced.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Data:\t[276  75  26   9   9]\n",
      "Training Data:\t[221  60  21   7   7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data:\t[55 15  5  2  2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Construct a DataFrame that holds the feature names (excluding the label column)\n",
    "feature_names = data.drop(['Dalc'], axis=1).columns.values\n",
    "feature_names\n",
    "\n",
    "# Construct a NumPy array that holds the different classes\n",
    "class_names = data.Dalc.unique()\n",
    "class_names\n",
    "\n",
    "# Split your data into a training set and a test set (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['Dalc'], axis=1), data.Dalc, test_size=0.2, random_state=RSEED, stratify=data.Dalc)\n",
    "\n",
    "fig = plt.figure(figsize=(15,3))\n",
    "# Complete Data\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.barh(np.arange(1, 6)[::-1], np.array(data.Dalc.value_counts().sort_values()))\n",
    "ax1.title.set_text('Complete Dalc Ratios')\n",
    "ax1.set_xlabel('Frequency')\n",
    "ax1.set_ylabel('Class')\n",
    "print(f\"Complete Data:\\t{np.array(data.Dalc.value_counts())}\")\n",
    "# Training Data\n",
    "ax2 = fig.add_subplot(132)\n",
    "plt.barh(np.arange(1, 6)[::-1], np.array(y_train.value_counts().sort_values()))\n",
    "ax2.title.set_text('Training Dalc Ratios')\n",
    "ax2.set_xlabel('Frequency')\n",
    "ax2.set_ylabel('Class')\n",
    "print(f\"Training Data:\\t{np.array(y_train.value_counts())}\")\n",
    "# Test Data\n",
    "ax3 = fig.add_subplot(133)\n",
    "plt.barh(np.arange(1, 6)[::-1], np.array(y_test.value_counts().sort_values()))\n",
    "ax3.title.set_text('Test Dalc Ratios')\n",
    "ax3.set_xlabel('Frequency')\n",
    "ax3.set_ylabel('Class')\n",
    "plt.show()\n",
    "print(f\"Test Data:\\t{np.array(y_test.value_counts())}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite this class imbalance, you should now train a decision tree classifier on the data as is.\n",
    "* <div style=\"color:blue\">As in the first part of the ML exercise, please define the feature matrix as <code>X</code> and the target variable as <code>y</code>. </div>\n",
    "* <div style=\"color:blue\">For model training, implement a <code>DecisionTreeClassifier</code> for which parameters have been tuned using cross-validated grid search.</div>\n",
    "* <div style=\"color:blue\">The parameters we are interested in are:</div>\n",
    "\n",
    "    * `max_depth` - using the values: [3, 4]\n",
    "    * `min_samples_split` - using the values: [2, 3, 4, 5]\n",
    "    * `min_samples_leaf` - using the values: [2, 3, 4, 5]\n",
    "* <div style=\"color:blue\">Explicitly set the <code>criterion</code> parameter of your classifier to <code>entropy</code>.</div>\n",
    "* <div style=\"color:blue\">Don't forget to eventually <b>fit</b> your model, using optimized parameters.</div>\n",
    "\n",
    "**Note**: This time around, we are not asking to create a separate test set to perform hold-out-validation. As our data is very sparse, and validation is already performed using cross-validation, this should be the right call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <div style=\"color:blue\">Print out the parameters for <code>max_depth</code>, <code>min_samples_split</code>, and <code>min_samples_leaf</code> for the best estimator found during grid search.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 3\n",
      "Best min_samples_leaf: 2\n",
      "Best min_samples_split: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a dictionary that holds all values we want to test for the given parameter\n",
    "parameters = {'max_depth':[3,4], 'min_samples_split':[2,3,4,5], 'min_samples_leaf':[2,3,4,5]}\n",
    "\n",
    "# Perform grid search (with default score metric)\n",
    "gs = GridSearchCV(tree.DecisionTreeClassifier(random_state=RSEED, criterion='entropy'), \n",
    "                  parameters)\n",
    "# Fit the model, using optimized parameters\n",
    "dtree_opt = gs.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Print the optimized parameters\n",
    "print('Best max_depth:', gs.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_leaf:', gs.best_estimator_.get_params()['min_samples_leaf'])\n",
    "print('Best min_samples_split:', gs.best_estimator_.get_params()['min_samples_split'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <div style=\"color:blue\">Get the accuracy score of your decision tree.</div>\n",
    "\n",
    "**Note**: If you have done everything correctly, your accuracy be around 70% at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6867063492063492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6455696202531646"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluate the performance of the decision tree using cross validation on the training data\n",
    "scores = cross_val_score(dtree_opt, X_train, y_train, cv=5)\n",
    "print(f\"Accuracy: {scores.mean()}\")\n",
    "\n",
    "# Evaluate the performance of the decision tree by checking the accuracy score on the test data\n",
    "dtree_opt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <div style=\"color:blue\">Display a scikit-learn <code>classification_report</code> of the best estimator on the whole dataset. How are the different classes represented?</div>\n",
    "\n",
    "**Note:** You can use the `print()` function to properly display the matrix inside a jupyter notebook. Also `zero_division=0` could help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.87      0.78       208\n",
      "         1.0       0.80      0.60      0.69       187\n",
      "\n",
      "    accuracy                           0.74       395\n",
      "   macro avg       0.76      0.73      0.73       395\n",
      "weighted avg       0.75      0.74      0.74       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your solution goes here:\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict using the best estimator on the whole dataset\n",
    "y_pred = grid_search.best_estimator_.predict(X)\n",
    "\n",
    "# Display the classification report\n",
    "report = classification_report(y, y_pred, zero_division=0)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to employ another technique to deal with data imbalance and train a more balanced and less biased model. As usual, depending on the data, the use-case, and your personal experience, there are many techniques you could try to implement in order to circumvent or mitigate imbalanced classes. [This website](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/), for example, lists a number of reasonable suggestions to tackle this issue.\n",
    "\n",
    "In this exercise you should implement an **oversampling** approach. For this, you should install [imbalanced-learn](https://imbalanced-learn.org/stable/index.html) (eg. via `mamba install imbalanced-learn`) and use their [random oversampling class](https://imbalanced-learn.org/stable/over_sampling.html).\n",
    "* <div style=\"color:blue\">Instantiate a <code>RandomOverSampler</code> from <code>imbalanced-learn</code> and resample your data.</div>\n",
    "* <div style=\"color:blue\">Make sure that all classes are represented equally!</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after resampling:\n",
      "sex\n",
      "0.0    208\n",
      "1.0    208\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Your solution goes here:\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate the RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Resample the training data\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Confirm class distribution after resampling\n",
    "print(\"Class distribution after resampling:\")\n",
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <div style=\"color:blue\">Now use the same modeling pipeline as before. Implement a <code>DecisionTreeClassifier</code> for which parameters have been tuned using cross-validated grid search. Use the same parameters as before</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "Best Cross-Validation Score: 0.673235800344234\n"
     ]
    }
   ],
   "source": [
    "# use the same grid search to find the best parameters\n",
    "grid_search_r = GridSearchCV(clf_resampled, param_grid_resampled, cv=5, scoring='accuracy')\n",
    "grid_search_r.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Print params\n",
    "print(\"Best Parameters:\", grid_search_r.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid_search_r.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <div style=\"color:blue\">Finally, display a scikit-learn <code>classification_report</code> of the best estimator on the whole, original dataset.</div>\n",
    "* <div style=\"color:blue\">How has the classification changed? Please explain why this approach might be favorable for use-cases with rare and sensitive classes (think about <b>rare diseases</b> for example!)</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on the original dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.86      0.77       208\n",
      "         1.0       0.79      0.57      0.66       187\n",
      "\n",
      "    accuracy                           0.72       395\n",
      "   macro avg       0.74      0.72      0.71       395\n",
      "weighted avg       0.74      0.72      0.72       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate predictions on the original dataset using the best estimator\n",
    "y_pred = grid_search_r.best_estimator_.predict(X)\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report on the original dataset:\")\n",
    "print(classification_report(y, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *although we can see the recall and f1-score are lower than in the first case, we can observe the precision increased after resampling;\n",
    "##### *the model can become too \"confident\" and miss some actual cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
